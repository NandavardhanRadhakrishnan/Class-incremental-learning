{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t4F90-rB4LbC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "E54FlCcw4LbG"
      },
      "outputs": [],
      "source": [
        "def create_mnist_data(num_classes, task_index,csv_file=\"mnist.csv\", image_shape=(1, 28, 28)):\n",
        "    mnist_file = open(csv_file)\n",
        "    df = pd.read_csv(mnist_file)\n",
        "\n",
        "    all_classes = sorted(df['label'].unique())\n",
        "    start_class = task_index * num_classes\n",
        "    end_class = start_class + num_classes\n",
        "    valid_classes = all_classes[start_class:end_class]\n",
        "\n",
        "\n",
        "    filtered_df = df[df['label'].isin(valid_classes)]\n",
        "\n",
        "\n",
        "    X = filtered_df.drop(columns=['label']).values\n",
        "    y = filtered_df['label'].values\n",
        "\n",
        "\n",
        "    X = torch.tensor(X / 255.0, dtype=torch.float32)\n",
        "    X = X.view(-1, *image_shape)\n",
        "    y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    return TensorDataset(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JLuLeQHcBW_E"
      },
      "outputs": [],
      "source": [
        "def inference_on_model(model, loader, num_classes):\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, labels) in enumerate(loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "            if len(images.shape) == 3:\n",
        "                images = images.unsqueeze(1)\n",
        "\n",
        "            logits = model(images)\n",
        "            predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "            all_preds.extend(predictions.cpu().numpy())\n",
        "\n",
        "            if labels.ndimension() == 0:\n",
        "                labels = labels.unsqueeze(0)\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            if batch_idx % 2000 == 0:\n",
        "                print(f\"Batch {batch_idx} Predictions:\")\n",
        "                print(f\"Predicted: {predictions.cpu().numpy()}\")\n",
        "                print(f\"True:      {labels.cpu().numpy()}\")\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(num_classes)))\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=list(range(num_classes)),\n",
        "                yticklabels=list(range(num_classes)))\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "    print(cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LYN76Q3zBW_F"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.max_pool2d(x, 2, 2)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.max_pool2d(x, 2, 2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8Vynw8Z9BW_G"
      },
      "outputs": [],
      "source": [
        "def train_model(model, data_loader, criterion, optimizer, epochs, device):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        with tqdm(total=len(data_loader), desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\") as pbar:\n",
        "            for X_batch, y_batch in data_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(X_batch)\n",
        "                loss = criterion(outputs, y_batch)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "                pbar.set_postfix(loss=total_loss / (pbar.n + 1))\n",
        "                pbar.update(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NoIbvWWbBW_I"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "    return correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes_per_task = [5, 5]\n",
        "image_shape = (1, 28, 28)\n",
        "\n",
        "task1_data = create_mnist_data(num_classes_per_task[0], task_index=0, image_shape=image_shape)\n",
        "task2_data = create_mnist_data(num_classes_per_task[1], task_index=1, image_shape=image_shape)\n",
        "data = create_mnist_data(10, task_index=0, image_shape=image_shape)\n",
        "\n",
        "task_data = [(task1_data, task1_data), (task2_data, task2_data)]\n",
        "\n",
        "batch_size = 64\n",
        "task1_loader = DataLoader(task1_data, batch_size=batch_size, shuffle=True)\n",
        "task2_loader = DataLoader(task2_data, batch_size=batch_size, shuffle=True)\n",
        "combined_data_loader = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "XEsgBxaYCXOS",
        "outputId": "14151ecc-d7d8-42dd-99ae-45b436637957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'mnist.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-99ae94f7c435>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimage_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtask1_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mnist_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes_per_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtask2_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mnist_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes_per_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mnist_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-a780a5735c9c>\u001b[0m in \u001b[0;36mcreate_mnist_data\u001b[0;34m(num_classes, task_index, csv_file, image_shape)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_mnist_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mnist.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmnist_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mnist.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm3jyvYvBW_J"
      },
      "source": [
        "# Finetuning Approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZOxDCu2BW_M"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "model = SimpleCNN(num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train on task 1\n",
        "print(\"Training on Task 1...\")\n",
        "train_model(model, task1_loader, criterion, optimizer, epochs=5, device=device)\n",
        "accuracy_task1 = evaluate_model(model, task1_loader, device)\n",
        "print(f\"Accuracy on Task 1: {accuracy_task1:.2f}\")\n",
        "\n",
        "# Fine-tune on task 2 with reduced learning rate\n",
        "print(\"Fine-tuning on Task 2...\")\n",
        "for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = 0.00001  # Reduce learning rate\n",
        "\n",
        "train_model(model, task2_loader, criterion, optimizer, epochs=5, device=device)\n",
        "accuracy_task2 = evaluate_model(model, task2_loader, device)\n",
        "print(f\"Accuracy on Task 2: {accuracy_task2:.2f}\")\n",
        "\n",
        "# Final evaluation on all classes\n",
        "accuracy_combined = evaluate_model(model, combined_data_loader, device)\n",
        "print(f\"Final Accuracy on All Classes: {accuracy_combined:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laMwpcYj47I2"
      },
      "outputs": [],
      "source": [
        "inference_on_model(model,combined_data_loader,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7rkeMqABW_N"
      },
      "source": [
        "# Knowledge Distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iP6GadzU48qD"
      },
      "outputs": [],
      "source": [
        "def train_model_with_kd(student, teacher, data_loader, optimizer, criterion_ce, criterion_kd, alpha, temperature, epochs, device):\n",
        "    student.train()\n",
        "    teacher.eval()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        with tqdm(total=len(data_loader), desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\") as pbar:\n",
        "            for X_batch, y_batch in data_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                student_outputs = student(X_batch)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    teacher_outputs = teacher(X_batch)\n",
        "\n",
        "                kd_loss = criterion_kd(\n",
        "                    nn.functional.log_softmax(student_outputs / temperature, dim=1),\n",
        "                    nn.functional.softmax(teacher_outputs / temperature, dim=1)\n",
        "                ) * (temperature ** 2)\n",
        "\n",
        "                ce_loss = criterion_ce(student_outputs, y_batch)\n",
        "\n",
        "                loss = alpha * kd_loss + (1 - alpha) * (ce_loss * 2)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                pbar.set_postfix(loss=total_loss / (pbar.n + 1))\n",
        "                pbar.update(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNFZKCnGBW_O"
      },
      "outputs": [],
      "source": [
        "teacher_model = SimpleCNN(num_classes=num_classes).to(device)\n",
        "student_model = SimpleCNN(num_classes=num_classes).to(device)\n",
        "\n",
        "criterion_ce = nn.CrossEntropyLoss()\n",
        "criterion_kd = nn.KLDivLoss(reduction='batchmean')\n",
        "optimizer_teacher = optim.Adam(teacher_model.parameters(), lr=0.001)\n",
        "optimizer_student = optim.Adam(student_model.parameters(), lr=0.0005)\n",
        "\n",
        "# Train teacher on Task 1\n",
        "print(\"Training Teacher Model on Task 1...\")\n",
        "train_model(teacher_model, task1_loader, criterion_ce, optimizer_teacher, epochs=5, device=device)\n",
        "accuracy_task1 = evaluate_model(teacher_model, task1_loader, device)\n",
        "print(f\"Teacher Model Accuracy on Task 1: {accuracy_task1:.2f}\")\n",
        "\n",
        "# Fine-tune student on Task 2 with KD\n",
        "print(\"Fine-tuning Student Model on Task 2 using KD...\")\n",
        "alpha = 0.5\n",
        "temperature = 1.0\n",
        "train_model_with_kd(\n",
        "    student=student_model,\n",
        "    teacher=teacher_model,\n",
        "    data_loader=task2_loader,\n",
        "    optimizer=optimizer_student,\n",
        "    criterion_ce=criterion_ce,\n",
        "    criterion_kd=criterion_kd,\n",
        "    alpha=alpha,\n",
        "    temperature=temperature,\n",
        "    epochs=5,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# Evaluate student on all classes\n",
        "accuracy_combined = evaluate_model(student_model, combined_data_loader, device)\n",
        "print(f\"Student Model Final Accuracy on All Classes: {accuracy_combined:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD8bbtv46xh4"
      },
      "outputs": [],
      "source": [
        "inference_on_model(student_model,combined_data_loader,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9_heeU_7CjF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}