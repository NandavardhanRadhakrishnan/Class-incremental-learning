{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnistFile = open(\"mnist.csv\")\n",
    "df = pd.read_csv(mnistFile)\n",
    "numbers = sorted(list(set(df[\"label\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(df.iloc[1, 1:].values.reshape(28, 28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base train shape: (20168, 784) (20168,)\n",
      "Base test shape: (5043, 784) (5043,)\n",
      "Extra train shape: (13431, 784) (13431,)\n",
      "Extra test shape: (3358, 784) (3358,)\n",
      "Whole train shape: (33600, 784) (33600,)\n",
      "Whole test shape: (8400, 784) (8400,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into base (0-5) and extra (6-9)\n",
    "base_df = df[df['label'].isin([0, 1, 2, 3, 4, 5])]\n",
    "extra_df = df[df['label'].isin([6, 7, 8, 9])]\n",
    "\n",
    "# Split the features and labels\n",
    "X_base = base_df.drop(columns=['label'])\n",
    "y_base = base_df['label']\n",
    "X_extra = extra_df.drop(columns=['label'])\n",
    "y_extra = extra_df['label']\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Perform train-test split for base, extra, and whole dataset\n",
    "X_base_train, X_base_test, y_base_train, y_base_test = train_test_split(X_base, y_base, test_size=0.2, random_state=42)\n",
    "X_extra_train, X_extra_test, y_extra_train, y_extra_test = train_test_split(X_extra, y_extra, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the splits\n",
    "print(\"Base train shape:\", X_base_train.shape, y_base_train.shape)\n",
    "print(\"Base test shape:\", X_base_test.shape, y_base_test.shape)\n",
    "print(\"Extra train shape:\", X_extra_train.shape, y_extra_train.shape)\n",
    "print(\"Extra test shape:\", X_extra_test.shape, y_extra_test.shape)\n",
    "print(\"Whole train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Whole test shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 33600\n",
      "Test dataset size: 8400\n",
      "Base train dataset size: 20168\n",
      "Base test dataset size: 5043\n",
      "Extra train dataset size: 13431\n",
      "Extra test dataset size: 3358\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "  def __init__(self, data, labels):\n",
    "    self.data = torch.tensor(data.values, dtype=torch.float32)\n",
    "    self.labels = torch.tensor(labels.values, dtype=torch.long)\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = MNISTDataset(X_train, y_train)\n",
    "test_dataset = MNISTDataset(X_test, y_test)\n",
    "base_train_dataset = MNISTDataset(X_base_train, y_base_train)\n",
    "base_test_dataset = MNISTDataset(X_base_test, y_base_test)\n",
    "extra_train_dataset = MNISTDataset(X_extra_train, y_extra_train)\n",
    "extra_test_dataset = MNISTDataset(X_extra_test, y_extra_test)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "base_train_loader = DataLoader(base_train_dataset, batch_size=64, shuffle=True)\n",
    "base_test_loader = DataLoader(base_test_dataset, batch_size=64, shuffle=False)\n",
    "extra_train_loader = DataLoader(extra_train_dataset, batch_size=64, shuffle=True)\n",
    "extra_test_loader = DataLoader(extra_test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Print the sizes of the datasets\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Test dataset size:\", len(test_dataset))\n",
    "print(\"Base train dataset size:\", len(base_train_dataset))\n",
    "print(\"Base test dataset size:\", len(base_test_dataset))\n",
    "print(\"Extra train dataset size:\", len(extra_train_dataset))\n",
    "print(\"Extra test dataset size:\", len(extra_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNModel(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "F = nn.functional\n",
    "class CNNModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNNModel, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "    self.fc2 = nn.Linear(128, 10)\n",
    "    self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "    x = x.view(-1, 64 * 7 * 7)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.dropout(x)\n",
    "    x = self.fc2(x)\n",
    "    return x\n",
    "\n",
    "# Instantiate the model, define the loss function and the optimizer\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, num_epochs=10):\n",
    "  model.train()\n",
    "  for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "      inputs = inputs.view(inputs.size(0), 1, 28, 28)  # Reshape inputs to (batch_size, 1, 28, 28)\n",
    "      \n",
    "      # Zero the parameter gradients\n",
    "      optimizer.zero_grad()\n",
    "      \n",
    "      # Forward pass\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      \n",
    "      # Backward pass and optimize\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Print statistics\n",
    "      running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 0.3871\n",
      "Epoch [2/2], Loss: 0.0376\n"
     ]
    }
   ],
   "source": [
    "train_model(model,criterion, optimizer,base_train_loader,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, loader):\n",
    "  model.eval()\n",
    "  all_preds = []\n",
    "  all_labels = []\n",
    "  with torch.no_grad():\n",
    "    for inputs, labels in loader:\n",
    "      inputs = inputs.view(inputs.size(0), 1, 28, 28)  # Reshape inputs to (batch_size, 1, 28, 28)\n",
    "      outputs = model(inputs)\n",
    "      _, preds = torch.max(outputs, 1)\n",
    "      all_preds.extend(preds.cpu().numpy())\n",
    "      all_labels.extend(labels.cpu().numpy())\n",
    " \n",
    "  accuracy = accuracy_score(all_labels, all_preds)\n",
    "  print(f\"Accuracy on base test set: {accuracy:.4f}\")\n",
    "\n",
    "  conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "  print(\"Confusion Matrix:\")\n",
    "  print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fisher_information(model, data_loader, criterion):\n",
    "  model.eval()\n",
    "  fisher_information = {}\n",
    "  for name, param in model.named_parameters():\n",
    "    fisher_information[name] = torch.zeros_like(param)\n",
    "\n",
    "  for inputs, labels in data_loader:\n",
    "    inputs = inputs.view(inputs.size(0), 1, 28, 28)\n",
    "    model.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "      fisher_information[name] += param.grad ** 2\n",
    "\n",
    "  for name, _ in fisher_information.items():\n",
    "    fisher_information[name] /= len(data_loader.dataset)\n",
    "\n",
    "  return fisher_information\n",
    "\n",
    "def ewc_loss(new_model, old_model, fisher_information, lambda_ewc):\n",
    "  loss = 0\n",
    "  for name, param in new_model.named_parameters():\n",
    "    old_param = old_model.state_dict()[name]\n",
    "    fisher = fisher_information[name]\n",
    "    loss += (fisher * (param - old_param) ** 2).sum()\n",
    "  return lambda_ewc * loss\n",
    "\n",
    "def train_with_ewc(new_model, old_model, fisher_information, criterion, optimizer, train_loader, lambda_ewc, num_epochs=10):\n",
    "  new_model.train()\n",
    "  for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "      inputs = inputs.view(inputs.size(0), 1, 28, 28)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = new_model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      ewc_penalty = ewc_loss(new_model, old_model, fisher_information, lambda_ewc)\n",
    "      total_loss = loss + ewc_penalty\n",
    "      total_loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += total_loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "def generate_pseudo_data(model, num_samples=1000):\n",
    "  model.eval()\n",
    "  pseudo_data = []\n",
    "  pseudo_labels = []\n",
    "  for _ in range(num_samples):\n",
    "    noise = torch.randn(1, 1, 28, 28)\n",
    "    with torch.no_grad():\n",
    "      output = model(noise)\n",
    "      _, label = torch.max(output, 1)\n",
    "      pseudo_data.append(noise.squeeze().numpy())\n",
    "      pseudo_labels.append(label.item())\n",
    "  return np.array(pseudo_data), np.array(pseudo_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewcModel = torch.load(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "pseudo_data, pseudo_labels = generate_pseudo_data(model, num_samples)\n",
    "\n",
    "pseudo_dataset = MNISTDataset(pd.DataFrame(pseudo_data.reshape(num_samples, -1)), pd.Series(pseudo_labels))\n",
    "pseudo_loader = DataLoader(pseudo_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "fisher_information = compute_fisher_information(model, pseudo_loader, criterion)\n",
    "\n",
    "train_with_ewc(ewcModel, model, fisher_information, criterion, optimizer, extra_train_loader, lambda_ewc=0.4, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(ewcModel,extra_test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
